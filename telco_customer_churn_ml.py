# -*- coding: utf-8 -*-
"""Telco-Customer-Churn-ML.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wtj-yH8Dgg8tHrs3sok0yHqudUsDpFhE
"""

############################################################## Telco-Customer-Churn Model ML #########################################################################

import kagglehub

# Download latest version
path = kagglehub.dataset_download("blastchar/telco-customer-churn")

print("Path to dataset files:", path)

df= pd.read_csv("WA_Fn-UseC_-Telco-Customer-Churn.csv")
df

df.isnull()

df.info()

df.describe()

df.columns

df[df['TotalCharges'] == " "]

# Replace ' ' with NaN and convert to numeric
df['TotalCharges'] = df['TotalCharges'].replace(' ', pd.NA)
df['TotalCharges'] = pd.to_numeric(df['TotalCharges'])

# Fill the missing values with 0
df['TotalCharges'].fillna(0, inplace=True)

# Create a list of the categorical columns to encode
categorical_cols = [
    'gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines',
    'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport',
    'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod', 'Churn'
]

from sklearn.preprocessing import LabelEncoder
# Initialize the LabelEncoder
le = LabelEncoder()

# Loop through each categorical column and apply the encoder
for col in categorical_cols:
    df[col] = le.fit_transform(df[col])

df

import pandas as pd
import pickle
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
import warnings
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier

# Suppress warnings
warnings.filterwarnings('ignore')

# Optional libraries
try:
    import xgboost as xgb
except ImportError:
    xgb = None
    print("⚠️ XGBoost is not installed. Skipping XGBoost.")

try:
    from catboost import CatBoostClassifier
except ImportError:
    CatBoostClassifier = None
    print("⚠️ CatBoost is not installed. Skipping CatBoost.")

# Features & target
X = df.drop(columns=['customerID', 'Churn'])
y = df['Churn']

# One-hot encode categorical features
X = pd.get_dummies(X)

# Encode target
le = LabelEncoder()
y = le.fit_transform(y)

# Split data
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# --- Models ---
models = {
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    "Random Forest": RandomForestClassifier(random_state=42),
    "AdaBoost": AdaBoostClassifier(random_state=42)
}

if xgb:
    models["XGBoost"] = xgb.XGBClassifier(
        use_label_encoder=False,
        eval_metric='logloss',
        random_state=42
    )

if CatBoostClassifier:
    models["CatBoost"] = CatBoostClassifier(verbose=0, random_state=42)

# --- Train & Evaluate ---
metrics = {}
trained_models = {}

for name, model in models.items():
    print(f"Training {name}...")
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    metrics[name] = {
        "Accuracy": accuracy_score(y_test, y_pred),
        "Precision": precision_score(y_test, y_pred),
        "Recall": recall_score(y_test, y_pred),
        "F1-Score": f1_score(y_test, y_pred)
    }
    trained_models[name] = model  # save trained model

# --- Results as DataFrame ---
results_df = pd.DataFrame(metrics).T
print("\n📊 Model Performance Comparison:\n")
print(results_df)

# Best model by Accuracy
best_model_name = results_df["Accuracy"].idxmax()
best_model = trained_models[best_model_name]
best_acc = results_df.loc[best_model_name, "Accuracy"]

print(f"\n🔥 Best Model: {best_model_name} with Accuracy {best_acc:.4f}")

# Optional -->
# --- Save Best Model as .pkl ---
# with open("best_model.pkl", "wb") as f:
#     pickle.dump(best_model, f)

# print("\n✅ Best model saved as 'best_model.pkl'")